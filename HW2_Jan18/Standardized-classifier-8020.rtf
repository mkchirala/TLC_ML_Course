{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf600
{\fonttbl\f0\fmodern\fcharset0 Courier-Bold;\f1\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red255\green255\blue255;\red0\green0\blue0;\red254\green212\blue213;
}
{\*\expandedcolortbl;;\cssrgb\c100000\c100000\c100000;\cssrgb\c0\c0\c0;\cssrgb\c100000\c86667\c86667;
}
\margl1440\margr1440\vieww13540\viewh25040\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\b\fs28 \cf0 \cb2 \expnd0\expndtw0\kerning0
\ul \ulc0 Standardized: with 80% train, 20% test
\f1\b0 \ulnone \
\
Nearest Neighbors  : \
              precision    recall  f1-score   support\
\
           0       0.75      0.86      0.80         7\
           1       0.97      0.94      0.95        32\
\
    accuracy                           0.92        39\
   macro avg       0.86      0.90      0.88        39\
weighted avg       0.93      0.92      0.93        39\
\
[[ 6  1]\
 [ 2 30]]\
\
\
Linear SVM  : \
              precision    recall  f1-score   support\
\
           0       1.00      0.43      0.60         7\
           1       0.89      1.00      0.94        32\
\
    accuracy                           0.90        39\
   macro avg       0.94      0.71      0.77        39\
weighted avg       0.91      0.90      0.88        39\
\
[[ 3  4]\
 [ 0 32]]\
\
\
RBF SVM  : \
              precision    recall  f1-score   support\
\
           0       1.00      0.29      0.44         7\
           1       0.86      1.00      0.93        32\
\
    accuracy                           0.87        39\
   macro avg       0.93      0.64      0.69        39\
weighted avg       0.89      0.87      0.84        39\
\
[[ 2  5]\
 [ 0 32]]\
\
\
Gaussian Process  : \
              precision    recall  f1-score   support\
\
           0       0.00      0.00      0.00         7\
           1       0.82      1.00      0.90        32\
\
    accuracy                           0.82        39\
   macro avg       0.41      0.50      0.45        39\
weighted avg       0.67      0.82      0.74        39\
\
[[ 0  7]\
 [ 0 32]]\
\
\
Decision Tree  : \
              precision    recall  f1-score   support\
\
           0       0.83      0.71      0.77         7\
           1       0.94      0.97      0.95        32\
\
    accuracy                           0.92        39\
   macro avg       0.89      0.84      0.86        39\
weighted avg       0.92      0.92      0.92        39\
\
[[ 5  2]\
 [ 1 31]]\
\
\
Random Forest  : \
              precision    recall  f1-score   support\
\
           0       1.00      0.43      0.60         7\
           1       0.89      1.00      0.94        32\
\
    accuracy                           0.90        39\
   macro avg       0.94      0.71      0.77        39\
weighted avg       0.91      0.90      0.88        39\
\
[[ 3  4]\
 [ 0 32]]\
\
\
\pard\pardeftab720\partightenfactor0
\cf0 \cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb4 /opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\
  'precision', 'predicted', average, warn_for)\
\pard\pardeftab720\partightenfactor0
\cf0 \cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2 Neural Net  : \
              precision    recall  f1-score   support\
\
           0       1.00      0.71      0.83         7\
           1       0.94      1.00      0.97        32\
\
    accuracy                           0.95        39\
   macro avg       0.97      0.86      0.90        39\
weighted avg       0.95      0.95      0.95        39\
\
[[ 5  2]\
 [ 0 32]]\
\
\
AdaBoost  : \
              precision    recall  f1-score   support\
\
           0       0.67      0.57      0.62         7\
           1       0.91      0.94      0.92        32\
\
    accuracy                           0.87        39\
   macro avg       0.79      0.75      0.77        39\
weighted avg       0.87      0.87      0.87        39\
\
[[ 4  3]\
 [ 2 30]]\
\
\
Naive Bayes  : \
              precision    recall  f1-score   support\
\
           0       0.33      0.57      0.42         7\
           1       0.89      0.75      0.81        32\
\
    accuracy                           0.72        39\
   macro avg       0.61      0.66      0.62        39\
weighted avg       0.79      0.72      0.74        39\
\
[[ 4  3]\
 [ 8 24]]\
\
\
QDA  : \
              precision    recall  f1-score   support\
\
           0       1.00      0.43      0.60         7\
           1       0.89      1.00      0.94        32\
\
    accuracy                           0.90        39\
   macro avg       0.94      0.71      0.77        39\
weighted avg       0.91      0.90      0.88        39\
\
[[ 3  4]\
 [ 0 32]]}