{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSteps involved in linear regression analysis:\\n\\n1. Capture & clean data\\n    - Read data files in any format\\n    - Filter out & handle missing data\\n\\n2. Response & Predictors\\n    - Identify Predictor columns to define X\\n    - Identify Response columns to define Y  \\n    \\n3. Normalizing data & checks\\n    - Identify: Select numerical columns that need to be normalized\\n    - Execute: Import preprocessing & employ minmaxscaler function to normalize data\\n    - Validate: Make sure that correlation coefficients of normalized data looks similar to non-normalized data. \\n       This is doneby plotting out a correlation matrix and looking at correlation coefficients.\\n\\n4. Data Training\\n    - Data Split: Split data into training & test data sets. \\n                  Employ train_test_split to divide data into trainable & testable chunks     \\n    - Import training models from Python library sklearn.linear_model. Currently employing:\\n        - Linear Regression, Ridge, Lasso, LassoLars, BayesianRidge\\n    - Compare linear regression models with each other in terms of RMSE\\n    - Pick the correct training model  with lowest RMSE\\n\\n5. Apply model fit to predict\\n    - Fit the training data for predictors to responses\\n    - Print the \"parameters\" & intercept values\\n    - Employ the prediction model with the test values of X to predict\\n    - calculate the regression RMSE using sqrt(mean_squared_error(predict-target)) formula\\n    \\n6. Deploy the model\\n    - Come up with test data, use a dummy value for response\\n    - Normalize all column values, isolate all predictor values and convert it to a list of list\\n    - use .predict (normalized test data) to get the normalized test result \\n    - Put back the predicted test value into the list of lists\\n    - Perform an .inverse_transform(test transform) to denormalize the data\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Steps involved in linear regression analysis:\n",
    "\n",
    "1. Capture & clean data\n",
    "    - Read data files in any format\n",
    "    - Filter out & handle missing data\n",
    "\n",
    "2. Response & Predictors\n",
    "    - Identify Predictor columns to define X\n",
    "    - Identify Response columns to define Y  \n",
    "    \n",
    "3. Normalizing data & checks\n",
    "    - Identify: Select numerical columns that need to be normalized\n",
    "    - Execute: Import preprocessing & employ minmaxscaler function to normalize data\n",
    "    - Validate: Make sure that correlation coefficients of normalized data looks similar to non-normalized data. \n",
    "       This is doneby plotting out a correlation matrix and looking at correlation coefficients.\n",
    "\n",
    "4. Data Training\n",
    "    - Data Split: Split data into training & test data sets. \n",
    "                  Employ train_test_split to divide data into trainable & testable chunks     \n",
    "    - Import training models from Python library sklearn.linear_model. Currently employing:\n",
    "        - Linear Regression, Ridge, Lasso, LassoLars, BayesianRidge\n",
    "    - Compare linear regression models with each other in terms of RMSE\n",
    "    - Pick the correct training model  with lowest RMSE\n",
    "\n",
    "5. Apply model fit to predict\n",
    "    - Fit the training data for predictors to responses\n",
    "    - Print the \"parameters\" & intercept values\n",
    "    - Employ the prediction model with the test values of X to predict\n",
    "    - calculate the regression RMSE using sqrt(mean_squared_error(predict-target)) formula\n",
    "    \n",
    "6. Deploy the model\n",
    "    - Come up with test data, use a dummy value for response\n",
    "    - Normalize all column values, isolate all predictor values and convert it to a list of list\n",
    "    - use .predict (normalized test data) to get the normalized test result \n",
    "    - Put back the predicted test value into the list of lists\n",
    "    - Perform an .inverse_transform(test transform) to denormalize the data\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nD e f i n i t i o n s\\n\\nRegression, Linear & multi-variate\\n======\\n\\nRegression analysis is a statistical process to use an array of independent predictive elements to understand which \\nof those predictive elements have an impact on a desired prediction factor.\\n\\nThe analysis is either linear or non-linear in nature.\\n\\nA linear regression equation is one that has a linear dependency of predictors to a response. Specifically, a model \\nis linear when:\\n  - Each term is constant\\n  - Each term is a Product of a parameter(bk) & a predictor value (xk)\\n\\nA linear equation is constructed by adding the results for each term. They are of the  form:\\n\\nResponse = constant + parameter * predictor + ... + parameter * predictor + random error/noise\\nor \\n\\nY = b o + b1*X1 + b2*X2 + ... + bk*Xk + error \\n\\nNote that an expression is linear when it is linear in parameters. \\n\\nWhile the equation must be linear in the parameters, you can transform the predictor variables in ways that \\nproduce curvature. For instance, you can include a squared variable to produce a U-shaped curve.\\n\\nY = b o + b1*X1 + b2*X1^2 + .... + bk*Xk^k + error\\n\\nRegression, Non-linear\\n====\\nMore complex forms that do not involve each term being a straight forward product of a parameter & predictor values.\\n\\nExamples: Fourier, Weibull expressions, cosine & trigonometric expressions\\n\\nPower (convex): Theta1 * X^Theta2\\nWeibull growth: Theta1 + (Theta2 - Theta1) * exp(-Theta3) * X^Theta4\\nFourier: Theta1 * cos(X + Theta4) + (Theta2 * cos(2*X + Theta4) + Theta3\\n\\n\\nSignificance of Normalization\\n======\\nNormalization is a technique to change the values of numerical columns in a data set to a common scale, without \\ndistoring differences in the range of values. \\n\\nNot every data set requires normalization, only those that have predictor elements in different value ranges.\\n\\nThis is to avoid some predictors from disproportionately influencing the outcome of a prediction due to their larger values.\\n\\nFor ex:\\nConsider a data set containing two features, age(x1), and income(x2), very different in range. \\nWhere age ranges from 0–100, while income ranges from 0–20,000 and higher. \\nIncome is about 1,000 times larger than age and ranges from 20,000–500,000. \\nDue to its larger range, the attributed income will intrinsically influence the result. \\nBut this doesn’t necessarily mean it is more important as a predictor.\\nHence, Normalization is needed.\\n\\n## However, I have found this not to be true with the dataset that I had studied below\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "D e f i n i t i o n s\n",
    "\n",
    "Regression, Linear & multi-variate\n",
    "======\n",
    "\n",
    "Regression analysis is a statistical process to use an array of independent predictive elements to understand which \n",
    "of those predictive elements have an impact on a desired prediction factor.\n",
    "\n",
    "The analysis is either linear or non-linear in nature.\n",
    "\n",
    "A linear regression equation is one that has a linear dependency of predictors to a response. Specifically, a model \n",
    "is linear when:\n",
    "  - Each term is constant\n",
    "  - Each term is a Product of a parameter(bk) & a predictor value (xk)\n",
    "\n",
    "A linear equation is constructed by adding the results for each term. They are of the  form:\n",
    "\n",
    "Response = constant + parameter * predictor + ... + parameter * predictor + random error/noise\n",
    "or \n",
    "\n",
    "Y = b o + b1*X1 + b2*X2 + ... + bk*Xk + error \n",
    "\n",
    "Note that an expression is linear when it is linear in parameters. \n",
    "\n",
    "While the equation must be linear in the parameters, you can transform the predictor variables in ways that \n",
    "produce curvature. For instance, you can include a squared variable to produce a U-shaped curve.\n",
    "\n",
    "Y = b o + b1*X1 + b2*X1^2 + .... + bk*Xk^k + error\n",
    "\n",
    "Regression, Non-linear\n",
    "====\n",
    "More complex forms that do not involve each term being a straight forward product of a parameter & predictor values.\n",
    "\n",
    "Examples: Fourier, Weibull expressions, cosine & trigonometric expressions\n",
    "\n",
    "Power (convex): Theta1 * X^Theta2\n",
    "Weibull growth: Theta1 + (Theta2 - Theta1) * exp(-Theta3) * X^Theta4\n",
    "Fourier: Theta1 * cos(X + Theta4) + (Theta2 * cos(2*X + Theta4) + Theta3\n",
    "\n",
    "\n",
    "Significance of Normalization\n",
    "======\n",
    "Normalization is a technique to change the values of numerical columns in a data set to a common scale, without \n",
    "distoring differences in the range of values. \n",
    "\n",
    "Not every data set requires normalization, only those that have predictor elements in different value ranges.\n",
    "\n",
    "This is to avoid some predictors from disproportionately influencing the outcome of a prediction due to their larger values.\n",
    "\n",
    "For ex:\n",
    "Consider a data set containing two features, age(x1), and income(x2), very different in range. \n",
    "Where age ranges from 0–100, while income ranges from 0–20,000 and higher. \n",
    "Income is about 1,000 times larger than age and ranges from 20,000–500,000. \n",
    "Due to its larger range, the attributed income will intrinsically influence the result. \n",
    "But this doesn’t necessarily mean it is more important as a predictor.\n",
    "Hence, Normalization is needed.\n",
    "\n",
    "## However, I have found this not to be true with the dataset that I had studied below\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nNormalization vs Standardization\\n======\\n\\n\"https://www.statisticshowto.datasciencecentral.com/normalized/\"\\n\\nNormalization refers to scaling a variable to have values between 0 to 1. This is also known as \"feature scaling\".\\nMathematically, Xnew = (X - xmin)/(xmax - xmin)\\n\\n\\nStandardization refers to scaling data such that it has 0 mean and standard deviation of 1. \\nThis is also called a z-score, and data points can be standardized as:\\nzi = (xi - mean(x))/sigma\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Normalization vs Standardization\n",
    "======\n",
    "\n",
    "\"https://www.statisticshowto.datasciencecentral.com/normalized/\"\n",
    "\n",
    "Normalization refers to scaling a variable to have values between 0 to 1. This is also known as \"feature scaling\".\n",
    "Mathematically, Xnew = (X - xmin)/(xmax - xmin)\n",
    "\n",
    "\n",
    "Standardization refers to scaling data such that it has 0 mean and standard deviation of 1. \n",
    "This is also called a z-score, and data points can be standardized as:\n",
    "zi = (xi - mean(x))/sigma\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Try to see if Normalization makes any difference to Homeprices in C1_Student_PyforML exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import math\n",
    "import statistics\n",
    "from scipy.stats import zscore\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SoSJ_housing_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeAge</th>\n",
       "      <th>HomeSqft</th>\n",
       "      <th>LotSize</th>\n",
       "      <th>BedRooms</th>\n",
       "      <th>HighSchoolAPI</th>\n",
       "      <th>ProxFwy</th>\n",
       "      <th>CarGarage</th>\n",
       "      <th>HomePriceK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>1615.280000</td>\n",
       "      <td>7840.500000</td>\n",
       "      <td>2.71000</td>\n",
       "      <td>904.610000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>1080.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>4.925711</td>\n",
       "      <td>231.759719</td>\n",
       "      <td>1046.107306</td>\n",
       "      <td>0.71485</td>\n",
       "      <td>36.166253</td>\n",
       "      <td>0.758787</td>\n",
       "      <td>1.234848</td>\n",
       "      <td>146.533583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1215.000000</td>\n",
       "      <td>6056.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>851.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>809.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>1411.500000</td>\n",
       "      <td>7024.250000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>875.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>940.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1606.500000</td>\n",
       "      <td>7822.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>901.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>1836.000000</td>\n",
       "      <td>8839.250000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>936.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>9476.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>975.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1336.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          HomeAge     HomeSqft      LotSize   BedRooms  HighSchoolAPI  \\\n",
       "count  100.000000   100.000000   100.000000  100.00000     100.000000   \n",
       "mean    17.200000  1615.280000  7840.500000    2.71000     904.610000   \n",
       "std      4.925711   231.759719  1046.107306    0.71485      36.166253   \n",
       "min     10.000000  1215.000000  6056.000000    2.00000     851.000000   \n",
       "25%     12.750000  1411.500000  7024.250000    2.00000     875.750000   \n",
       "50%     17.000000  1606.500000  7822.000000    3.00000     901.500000   \n",
       "75%     21.250000  1836.000000  8839.250000    3.00000     936.000000   \n",
       "max     25.000000  1994.000000  9476.000000    4.00000     975.000000   \n",
       "\n",
       "          ProxFwy   CarGarage   HomePriceK  \n",
       "count  100.000000  100.000000   100.000000  \n",
       "mean     3.100000    1.520000  1080.990000  \n",
       "std      0.758787    1.234848   146.533583  \n",
       "min      2.000000    0.000000   809.000000  \n",
       "25%      3.000000    0.000000   940.000000  \n",
       "50%      3.000000    2.000000  1100.000000  \n",
       "75%      4.000000    3.000000  1191.000000  \n",
       "max      4.000000    3.000000  1336.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape:  (100, 8) \n",
      "\n",
      "    HomeAge  HomeSqft   LotSize  BedRooms  HighSchoolAPI  ProxFwy  CarGarage  \\\n",
      "0  0.266667  0.516046  0.683626       0.0       0.000000      0.0   0.000000   \n",
      "1  0.200000  0.183569  0.223099       0.0       0.000000      0.5   0.666667   \n",
      "2  0.800000  0.653402  0.375146       0.5       1.000000      0.5   1.000000   \n",
      "3  0.133333  0.934531  0.348830       0.0       0.991935      0.0   0.000000   \n",
      "4  0.200000  0.797176  0.283918       0.0       0.927419      0.5   1.000000   \n",
      "\n",
      "   HomePriceK  \n",
      "0    0.624288  \n",
      "1    0.094877  \n",
      "2    0.434535  \n",
      "3    0.419355  \n",
      "4    0.199241  \n"
     ]
    }
   ],
   "source": [
    "float_array = df.values.astype(float)\n",
    "min_max_scaler = preprocessing.MinMaxScaler() # min = 0; max =1 --> all values  will  be scaled in this  range\n",
    "scaled_array = min_max_scaler.fit_transform(float_array)\n",
    "df_normalized = pd.DataFrame(scaled_array,columns = [\"HomeAge\",\"HomeSqft\",\"LotSize\",\"BedRooms\",\"HighSchoolAPI\",\"ProxFwy\",\"CarGarage\",\"HomePriceK\"])\n",
    "print(\"Dataframe shape: \",df_normalized.shape,\"\\n\") # \n",
    "print(df_normalized[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(df):\n",
    "    from matplotlib import pyplot as plt\n",
    "    from matplotlib import cm as cm\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    cmap = cm.get_cmap('RdYlBu', 30)\n",
    "    labels = [\"m\",\"HomeAge\",\"HomeSqft\",\"LotSize\",\"BedRooms\",\"HighSchoolAPI\",\"ProxFwy\",\"CarGarage\",\"HomePriceK\"]\n",
    "    cax = ax1.imshow(df.corr(), interpolation=\"nearest\", cmap=cmap)\n",
    "    ax1.grid(True)\n",
    "    ax1.set_xticklabels(labels,fontsize=6)\n",
    "    ax1.set_yticklabels(labels,fontsize=6)\n",
    "    # Add colorbar, make sure to specify tick locations to match desired ticklabels\n",
    "    fig.colorbar(cax, ticks=[0.7,.75,.8,.85,.90,.95,1])\n",
    "    plt.show() # for large data sets model convergence is faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeAge</th>\n",
       "      <th>HomeSqft</th>\n",
       "      <th>LotSize</th>\n",
       "      <th>BedRooms</th>\n",
       "      <th>HighSchoolAPI</th>\n",
       "      <th>ProxFwy</th>\n",
       "      <th>CarGarage</th>\n",
       "      <th>HomePriceK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>HomeAge</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>0.133927</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>-0.004151</td>\n",
       "      <td>-0.035133</td>\n",
       "      <td>-0.100304</td>\n",
       "      <td>0.154894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HomeSqft</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.084197</td>\n",
       "      <td>0.032016</td>\n",
       "      <td>0.046302</td>\n",
       "      <td>-0.035486</td>\n",
       "      <td>-0.046856</td>\n",
       "      <td>-0.051960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LotSize</td>\n",
       "      <td>0.133927</td>\n",
       "      <td>-0.084197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.529351</td>\n",
       "      <td>-0.141361</td>\n",
       "      <td>-0.146570</td>\n",
       "      <td>-0.023795</td>\n",
       "      <td>0.962220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BedRooms</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.032016</td>\n",
       "      <td>0.529351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.098336</td>\n",
       "      <td>0.054004</td>\n",
       "      <td>0.012358</td>\n",
       "      <td>0.510955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HighSchoolAPI</td>\n",
       "      <td>-0.004151</td>\n",
       "      <td>0.046302</td>\n",
       "      <td>-0.141361</td>\n",
       "      <td>0.098336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.087640</td>\n",
       "      <td>0.104783</td>\n",
       "      <td>-0.137037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ProxFwy</td>\n",
       "      <td>-0.035133</td>\n",
       "      <td>-0.035486</td>\n",
       "      <td>-0.146570</td>\n",
       "      <td>0.054004</td>\n",
       "      <td>-0.087640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.073306</td>\n",
       "      <td>-0.190496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CarGarage</td>\n",
       "      <td>-0.100304</td>\n",
       "      <td>-0.046856</td>\n",
       "      <td>-0.023795</td>\n",
       "      <td>0.012358</td>\n",
       "      <td>0.104783</td>\n",
       "      <td>0.073306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.055459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HomePriceK</td>\n",
       "      <td>0.154894</td>\n",
       "      <td>-0.051960</td>\n",
       "      <td>0.962220</td>\n",
       "      <td>0.510955</td>\n",
       "      <td>-0.137037</td>\n",
       "      <td>-0.190496</td>\n",
       "      <td>-0.055459</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                HomeAge  HomeSqft   LotSize  BedRooms  HighSchoolAPI  \\\n",
       "HomeAge        1.000000  0.005498  0.133927  0.005164      -0.004151   \n",
       "HomeSqft       0.005498  1.000000 -0.084197  0.032016       0.046302   \n",
       "LotSize        0.133927 -0.084197  1.000000  0.529351      -0.141361   \n",
       "BedRooms       0.005164  0.032016  0.529351  1.000000       0.098336   \n",
       "HighSchoolAPI -0.004151  0.046302 -0.141361  0.098336       1.000000   \n",
       "ProxFwy       -0.035133 -0.035486 -0.146570  0.054004      -0.087640   \n",
       "CarGarage     -0.100304 -0.046856 -0.023795  0.012358       0.104783   \n",
       "HomePriceK     0.154894 -0.051960  0.962220  0.510955      -0.137037   \n",
       "\n",
       "                ProxFwy  CarGarage  HomePriceK  \n",
       "HomeAge       -0.035133  -0.100304    0.154894  \n",
       "HomeSqft      -0.035486  -0.046856   -0.051960  \n",
       "LotSize       -0.146570  -0.023795    0.962220  \n",
       "BedRooms       0.054004   0.012358    0.510955  \n",
       "HighSchoolAPI -0.087640   0.104783   -0.137037  \n",
       "ProxFwy        1.000000   0.073306   -0.190496  \n",
       "CarGarage      0.073306   1.000000   -0.055459  \n",
       "HomePriceK    -0.190496  -0.055459    1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correlation_matrix(df) # original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeAge</th>\n",
       "      <th>HomeSqft</th>\n",
       "      <th>LotSize</th>\n",
       "      <th>BedRooms</th>\n",
       "      <th>HighSchoolAPI</th>\n",
       "      <th>ProxFwy</th>\n",
       "      <th>CarGarage</th>\n",
       "      <th>HomePriceK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>HomeAge</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>0.133927</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>-0.004151</td>\n",
       "      <td>-0.035133</td>\n",
       "      <td>-0.100304</td>\n",
       "      <td>0.154894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HomeSqft</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.084197</td>\n",
       "      <td>0.032016</td>\n",
       "      <td>0.046302</td>\n",
       "      <td>-0.035486</td>\n",
       "      <td>-0.046856</td>\n",
       "      <td>-0.051960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LotSize</td>\n",
       "      <td>0.133927</td>\n",
       "      <td>-0.084197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.529351</td>\n",
       "      <td>-0.141361</td>\n",
       "      <td>-0.146570</td>\n",
       "      <td>-0.023795</td>\n",
       "      <td>0.962220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BedRooms</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.032016</td>\n",
       "      <td>0.529351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.098336</td>\n",
       "      <td>0.054004</td>\n",
       "      <td>0.012358</td>\n",
       "      <td>0.510955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HighSchoolAPI</td>\n",
       "      <td>-0.004151</td>\n",
       "      <td>0.046302</td>\n",
       "      <td>-0.141361</td>\n",
       "      <td>0.098336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.087640</td>\n",
       "      <td>0.104783</td>\n",
       "      <td>-0.137037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ProxFwy</td>\n",
       "      <td>-0.035133</td>\n",
       "      <td>-0.035486</td>\n",
       "      <td>-0.146570</td>\n",
       "      <td>0.054004</td>\n",
       "      <td>-0.087640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.073306</td>\n",
       "      <td>-0.190496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CarGarage</td>\n",
       "      <td>-0.100304</td>\n",
       "      <td>-0.046856</td>\n",
       "      <td>-0.023795</td>\n",
       "      <td>0.012358</td>\n",
       "      <td>0.104783</td>\n",
       "      <td>0.073306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.055459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HomePriceK</td>\n",
       "      <td>0.154894</td>\n",
       "      <td>-0.051960</td>\n",
       "      <td>0.962220</td>\n",
       "      <td>0.510955</td>\n",
       "      <td>-0.137037</td>\n",
       "      <td>-0.190496</td>\n",
       "      <td>-0.055459</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                HomeAge  HomeSqft   LotSize  BedRooms  HighSchoolAPI  \\\n",
       "HomeAge        1.000000  0.005498  0.133927  0.005164      -0.004151   \n",
       "HomeSqft       0.005498  1.000000 -0.084197  0.032016       0.046302   \n",
       "LotSize        0.133927 -0.084197  1.000000  0.529351      -0.141361   \n",
       "BedRooms       0.005164  0.032016  0.529351  1.000000       0.098336   \n",
       "HighSchoolAPI -0.004151  0.046302 -0.141361  0.098336       1.000000   \n",
       "ProxFwy       -0.035133 -0.035486 -0.146570  0.054004      -0.087640   \n",
       "CarGarage     -0.100304 -0.046856 -0.023795  0.012358       0.104783   \n",
       "HomePriceK     0.154894 -0.051960  0.962220  0.510955      -0.137037   \n",
       "\n",
       "                ProxFwy  CarGarage  HomePriceK  \n",
       "HomeAge       -0.035133  -0.100304    0.154894  \n",
       "HomeSqft      -0.035486  -0.046856   -0.051960  \n",
       "LotSize       -0.146570  -0.023795    0.962220  \n",
       "BedRooms       0.054004   0.012358    0.510955  \n",
       "HighSchoolAPI -0.087640   0.104783   -0.137037  \n",
       "ProxFwy        1.000000   0.073306   -0.190496  \n",
       "CarGarage      0.073306   1.000000   -0.055459  \n",
       "HomePriceK    -0.190496  -0.055459    1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normalized.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correlation_matrix(df_normalized) # normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_normalized.drop('HomePriceK',axis=1)\n",
    "y = df_normalized['HomePriceK']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exercise 1: Study the impact of Normalization and compare its impact on different linear regression algorithms  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (75, 7)\n",
      "y_train shape:  (75,)\n",
      "X_test shape:  (25, 7)\n",
      "y_test shape:  (25,)\n"
     ]
    }
   ],
   "source": [
    "# Split data to training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split X and y into X_\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "print(\"X_train shape: \",X_train.shape) # 75 rows, 7 columns\n",
    "print(\"y_train shape: \",y_train.shape) # 75 rows, 1 column\n",
    "print(\"X_test shape: \",X_test.shape) # 25 rows, 7 columns\n",
    "print(\"y_test shape: \",y_test.shape) # 25 rows, 1 column\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Linear Regression RMSE:  0.07676601766438633\n"
     ]
    }
   ],
   "source": [
    "# fit normalized training data, predict a response and calculate the RMSE\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "y_predict = lm.predict(X_test)\n",
    "regression_model_mse = mean_squared_error(y_predict, y_test)\n",
    "print(\"Normalized Linear Regression RMSE: \",math.sqrt(regression_model_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized data: [[ 4.00000000e-01  7.83055199e-01  2.62865497e-01  5.00000000e-01\n",
      "  -8.06451613e-03  1.00000000e+00  1.00000000e+00  1.69242884e+02]]\n",
      "[[0.4, 0.7830551989730425, 0.26286549707602336, 0.5, -0.008064516129032029, 1.0, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "# give trial data and see how it works\n",
    "Test_data = np.array([[16,1825,6955,3,850,4,3,90000]])\n",
    "Test_data_norm = min_max_scaler.transform(Test_data)\n",
    "print(\"Normalized data:\",Test_data_norm)\n",
    "Test1 = [list(Test_data_norm[0][0:7])]\n",
    "print (Test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test result predicted (normalized) is:  0.27425169125086607\n"
     ]
    }
   ],
   "source": [
    "test_result = lm.predict(Test1)\n",
    "print (\"Test result predicted (normalized) is: \", test_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test row with predicted value is: [[ 0.4         0.7830552   0.2628655   0.5        -0.00806452  1.\n",
      "   1.          0.27425169]]\n"
     ]
    }
   ],
   "source": [
    "Test_data_norm[0][7] = test_result[0]   #replace existing value with predicted value\n",
    "print (\"test row with predicted value is:\", Test_data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test result:  [[1.60000000e+01 1.82500000e+03 6.95500000e+03 3.00000000e+00\n",
      "  8.50000000e+02 4.00000000e+00 3.00000000e+00 9.53530641e+02]]\n",
      "Predicted HomePriceK:  953.5306412892064\n"
     ]
    }
   ],
   "source": [
    "result = min_max_scaler.inverse_transform(Test_data_norm) # apply inverse transform\n",
    "print(\"Final test result: \",result)\n",
    "print(\"Predicted HomePriceK: \",result[0][7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparison with non-normalized approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df.drop('HomePriceK',axis=1)\n",
    "y2 = df['HomePriceK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X2_train shape:  (75, 7)\n",
      "y2_train shape:  (75,)\n",
      "X2_test shape:  (25, 7)\n",
      "y2_test shape:  (25,)\n"
     ]
    }
   ],
   "source": [
    "# Split data to training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split X and y into X_\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.25, random_state=1)\n",
    "print(\"X2_train shape: \",X2_train.shape) \n",
    "print(\"y2_train shape: \",y2_train.shape) \n",
    "print(\"X2_test shape: \",X2_test.shape) \n",
    "print(\"y2_test shape: \",y2_test.shape) \n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-normalized Linear Regression RMSE:   40.455691309131716\n"
     ]
    }
   ],
   "source": [
    "# fit non-normalized training data, predict a response and calculate the RMSE\n",
    "lm2 = LinearRegression()\n",
    "lm2.fit(X2_train,y2_train)\n",
    "y2_predict = lm2.predict(X2_test)\n",
    "regression_model2_mse = mean_squared_error(y2_predict, y2_test)\n",
    "print(\"Non-normalized Linear Regression RMSE:  \",math.sqrt(regression_model2_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data : [[   16  1825  6955     3   850     4     3 90000]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Test data :\", Test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16, 1825, 6955, 3, 850, 4, 3]]\n"
     ]
    }
   ],
   "source": [
    "# predict using the above test data\n",
    "# select portion of data to create test set\n",
    "\n",
    "Test2 = [list(Test_data[0][0:7])]\n",
    "print (Test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test result predicted (non-normalized) is:  953.5306412892062\n"
     ]
    }
   ],
   "source": [
    "Test_result2 = lm2.predict(Test2)\n",
    "print (\"Test result predicted (non-normalized) is: \", Test_result2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  comparison of fits between normalized and non-normalized for different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Linear_Regression', 'Ridge', 'Lasso', 'LassoLars', 'BayesianRidge'])\n"
     ]
    }
   ],
   "source": [
    "# Dictionary of models\n",
    "d_models = {\"Linear_Regression\": LinearRegression(),\n",
    "            \"Ridge\": Ridge(alpha=0.5),\n",
    "            \"Lasso\": Lasso(alpha=0.1),\n",
    "            \"LassoLars\": LassoLars(alpha=0.1),\n",
    "            \"BayesianRidge\": BayesianRidge()}\n",
    "models_list = d_models.keys()\n",
    "print(models_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear_Regression  normalized RMSE :  0.07676601766438633\n",
      "Predicted HomePriceK:  953.5306412892064\n",
      "\n",
      "\n",
      "Ridge  normalized RMSE :  0.07043484557315978\n",
      "Predicted HomePriceK:  967.3892273819806\n",
      "\n",
      "\n",
      "Lasso  normalized RMSE :  0.2785641515458047\n",
      "Predicted HomePriceK:  1068.2800000000002\n",
      "\n",
      "\n",
      "LassoLars  normalized RMSE :  0.2785641515458047\n",
      "Predicted HomePriceK:  1068.2800000000002\n",
      "\n",
      "\n",
      "BayesianRidge  normalized RMSE :  0.07576513424788761\n",
      "Predicted HomePriceK:  955.214255043949\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for regression_model in models_list:\n",
    "    regressor = d_models[regression_model]\n",
    "    regressor.fit(X_train,y_train)\n",
    "    y_predict = regressor.predict(X_test)\n",
    "    regression_model_mse = mean_squared_error(y_predict, y_test)\n",
    "    print(regression_model,\" normalized RMSE : \",math.sqrt(regression_model_mse))\n",
    "    test_result = regressor.predict(Test1)\n",
    "    #print (\"Test result predicted (normalized) is: \", test_result[0])\n",
    "    Test_data_norm[0][7] = test_result[0]   #replace existing value with predicted value\n",
    "    #print (\"test row with predicted value is:\", Test_data_norm)\n",
    "    result = min_max_scaler.inverse_transform(Test_data_norm) # apply inverse transform\n",
    "    #print(\"Final test result: \",result)\n",
    "    print(\"Predicted HomePriceK: \",result[0][7])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear_Regression  RMSE :  40.455691309131716\n",
      "Test result predicted (non-normalized) is:  953.5306412892062\n",
      "\n",
      "\n",
      "Ridge  RMSE :  40.44657248160054\n",
      "Test result predicted (non-normalized) is:  953.529618961304\n",
      "\n",
      "\n",
      "Lasso  RMSE :  40.4078426805018\n",
      "Test result predicted (non-normalized) is:  953.4489632329703\n",
      "\n",
      "\n",
      "LassoLars  RMSE :  39.39457786428023\n",
      "Test result predicted (non-normalized) is:  952.2262117906909\n",
      "\n",
      "\n",
      "BayesianRidge  RMSE :  39.917041511647994\n",
      "Test result predicted (non-normalized) is:  961.8791294848497\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for regression_model in models_list:\n",
    "    regressor = d_models[regression_model]\n",
    "    regressor.fit(X2_train,y2_train)\n",
    "    y2_predict = regressor.predict(X2_test)\n",
    "    regression_model_mse = mean_squared_error(y2_predict, y2_test)\n",
    "    print(regression_model,\" RMSE : \",math.sqrt(regression_model_mse))\n",
    "    Test_result2 = regressor.predict(Test2)\n",
    "    print (\"Test result predicted (non-normalized) is: \", Test_result2[0])\n",
    "    print (\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Conclusion: \n",
    "### Normalization with LinearRegression does not impact predicted outcome. But it improves predictability for BeyesianRidge while worsening it for Lasso, Ridge & LassoLars algorithms --> suggesting there is a dependency on the type of algorithm employed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exercise 2: Study the impact of \"Standardization\" of data on HomePriceK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy  df\n",
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns :  ['HomeAge_zscore', 'HomeSqft_zscore', 'LotSize_zscore', 'BedRooms_zscore', 'HighSchoolAPI_zscore', 'ProxFwy_zscore', 'CarGarage_zscore', 'HomePriceK_zscore']\n",
      "std deviation list : [4.925710736799946, 231.75971883122244, 1046.1073056572613, 0.7148497051899099, 36.166253314213776, 0.7587869106393283, 1.2348475553073277, 146.53358252660314] 8\n",
      "Mean list : [17.2, 1615.28, 7840.5, 2.71, 904.61, 3.1, 1.52, 1080.99] 8\n"
     ]
    }
   ],
   "source": [
    "# Create z-scores of all columns, create a new df with zscores\n",
    "\n",
    "# Store all means and Std Devs for each column in separate lists\n",
    "cols = list(df2.columns)\n",
    "Std_z=[]\n",
    "Mean_z=[]\n",
    "\n",
    "# For each column calculate its Zscore and append it as a new column in data frame\n",
    "for col in cols:\n",
    "    col_zscore = col + '_zscore'\n",
    "    df2[col_zscore] = (df2[col] - df2[col].mean())/df2[col].std(ddof=1)\n",
    "    Std_z.append(df2[col].std(ddof=1))\n",
    "    Mean_z.append(df2[col].mean())\n",
    "\n",
    "#New data frame containing only Z-scores    \n",
    "dfZ =  df2.iloc[:,8:16].copy()\n",
    "cols_z = list(dfZ.columns)\n",
    "print (\"columns : \", cols_z)\n",
    "print (\"std deviation list :\", Std_z, len(Std_z))\n",
    "print (\"Mean list :\", Mean_z, len(Std_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeAge</th>\n",
       "      <th>HomeSqft</th>\n",
       "      <th>LotSize</th>\n",
       "      <th>BedRooms</th>\n",
       "      <th>HighSchoolAPI</th>\n",
       "      <th>ProxFwy</th>\n",
       "      <th>CarGarage</th>\n",
       "      <th>HomePriceK</th>\n",
       "      <th>HomeAge_zscore</th>\n",
       "      <th>HomeSqft_zscore</th>\n",
       "      <th>LotSize_zscore</th>\n",
       "      <th>BedRooms_zscore</th>\n",
       "      <th>HighSchoolAPI_zscore</th>\n",
       "      <th>ProxFwy_zscore</th>\n",
       "      <th>CarGarage_zscore</th>\n",
       "      <th>HomePriceK_zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1617</td>\n",
       "      <td>8394</td>\n",
       "      <td>2</td>\n",
       "      <td>851</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1138</td>\n",
       "      <td>-0.649652</td>\n",
       "      <td>0.007421</td>\n",
       "      <td>0.529104</td>\n",
       "      <td>-0.993216</td>\n",
       "      <td>-1.482321</td>\n",
       "      <td>-1.449682</td>\n",
       "      <td>-1.230921</td>\n",
       "      <td>0.389058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1358</td>\n",
       "      <td>6819</td>\n",
       "      <td>2</td>\n",
       "      <td>851</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>859</td>\n",
       "      <td>-0.852669</td>\n",
       "      <td>-1.110115</td>\n",
       "      <td>-0.976477</td>\n",
       "      <td>-0.993216</td>\n",
       "      <td>-1.482321</td>\n",
       "      <td>-0.131789</td>\n",
       "      <td>0.388712</td>\n",
       "      <td>-1.514943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1724</td>\n",
       "      <td>7339</td>\n",
       "      <td>3</td>\n",
       "      <td>975</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1038</td>\n",
       "      <td>0.974479</td>\n",
       "      <td>0.469107</td>\n",
       "      <td>-0.479396</td>\n",
       "      <td>0.405680</td>\n",
       "      <td>1.946290</td>\n",
       "      <td>-0.131789</td>\n",
       "      <td>1.198529</td>\n",
       "      <td>-0.293380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1943</td>\n",
       "      <td>7249</td>\n",
       "      <td>2</td>\n",
       "      <td>974</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1030</td>\n",
       "      <td>-1.055685</td>\n",
       "      <td>1.414051</td>\n",
       "      <td>-0.565430</td>\n",
       "      <td>-0.993216</td>\n",
       "      <td>1.918639</td>\n",
       "      <td>-1.449682</td>\n",
       "      <td>-1.230921</td>\n",
       "      <td>-0.347975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1836</td>\n",
       "      <td>7027</td>\n",
       "      <td>2</td>\n",
       "      <td>966</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>914</td>\n",
       "      <td>-0.852669</td>\n",
       "      <td>0.952366</td>\n",
       "      <td>-0.777645</td>\n",
       "      <td>-0.993216</td>\n",
       "      <td>1.697439</td>\n",
       "      <td>-0.131789</td>\n",
       "      <td>1.198529</td>\n",
       "      <td>-1.139602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HomeAge  HomeSqft  LotSize  BedRooms  HighSchoolAPI  ProxFwy  CarGarage  \\\n",
       "0       14      1617     8394         2            851        2          0   \n",
       "1       13      1358     6819         2            851        3          2   \n",
       "2       22      1724     7339         3            975        3          3   \n",
       "3       12      1943     7249         2            974        2          0   \n",
       "4       13      1836     7027         2            966        3          3   \n",
       "\n",
       "   HomePriceK  HomeAge_zscore  HomeSqft_zscore  LotSize_zscore  \\\n",
       "0        1138       -0.649652         0.007421        0.529104   \n",
       "1         859       -0.852669        -1.110115       -0.976477   \n",
       "2        1038        0.974479         0.469107       -0.479396   \n",
       "3        1030       -1.055685         1.414051       -0.565430   \n",
       "4         914       -0.852669         0.952366       -0.777645   \n",
       "\n",
       "   BedRooms_zscore  HighSchoolAPI_zscore  ProxFwy_zscore  CarGarage_zscore  \\\n",
       "0        -0.993216             -1.482321       -1.449682         -1.230921   \n",
       "1        -0.993216             -1.482321       -0.131789          0.388712   \n",
       "2         0.405680              1.946290       -0.131789          1.198529   \n",
       "3        -0.993216              1.918639       -1.449682         -1.230921   \n",
       "4        -0.993216              1.697439       -0.131789          1.198529   \n",
       "\n",
       "   HomePriceK_zscore  \n",
       "0           0.389058  \n",
       "1          -1.514943  \n",
       "2          -0.293380  \n",
       "3          -0.347975  \n",
       "4          -1.139602  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeAge_zscore</th>\n",
       "      <th>HomeSqft_zscore</th>\n",
       "      <th>LotSize_zscore</th>\n",
       "      <th>BedRooms_zscore</th>\n",
       "      <th>HighSchoolAPI_zscore</th>\n",
       "      <th>ProxFwy_zscore</th>\n",
       "      <th>CarGarage_zscore</th>\n",
       "      <th>HomePriceK_zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.649652</td>\n",
       "      <td>0.007421</td>\n",
       "      <td>0.529104</td>\n",
       "      <td>-0.993216</td>\n",
       "      <td>-1.482321</td>\n",
       "      <td>-1.449682</td>\n",
       "      <td>-1.230921</td>\n",
       "      <td>0.389058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.852669</td>\n",
       "      <td>-1.110115</td>\n",
       "      <td>-0.976477</td>\n",
       "      <td>-0.993216</td>\n",
       "      <td>-1.482321</td>\n",
       "      <td>-0.131789</td>\n",
       "      <td>0.388712</td>\n",
       "      <td>-1.514943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.974479</td>\n",
       "      <td>0.469107</td>\n",
       "      <td>-0.479396</td>\n",
       "      <td>0.405680</td>\n",
       "      <td>1.946290</td>\n",
       "      <td>-0.131789</td>\n",
       "      <td>1.198529</td>\n",
       "      <td>-0.293380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-1.055685</td>\n",
       "      <td>1.414051</td>\n",
       "      <td>-0.565430</td>\n",
       "      <td>-0.993216</td>\n",
       "      <td>1.918639</td>\n",
       "      <td>-1.449682</td>\n",
       "      <td>-1.230921</td>\n",
       "      <td>-0.347975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.852669</td>\n",
       "      <td>0.952366</td>\n",
       "      <td>-0.777645</td>\n",
       "      <td>-0.993216</td>\n",
       "      <td>1.697439</td>\n",
       "      <td>-0.131789</td>\n",
       "      <td>1.198529</td>\n",
       "      <td>-1.139602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HomeAge_zscore  HomeSqft_zscore  LotSize_zscore  BedRooms_zscore  \\\n",
       "0       -0.649652         0.007421        0.529104        -0.993216   \n",
       "1       -0.852669        -1.110115       -0.976477        -0.993216   \n",
       "2        0.974479         0.469107       -0.479396         0.405680   \n",
       "3       -1.055685         1.414051       -0.565430        -0.993216   \n",
       "4       -0.852669         0.952366       -0.777645        -0.993216   \n",
       "\n",
       "   HighSchoolAPI_zscore  ProxFwy_zscore  CarGarage_zscore  HomePriceK_zscore  \n",
       "0             -1.482321       -1.449682         -1.230921           0.389058  \n",
       "1             -1.482321       -0.131789          0.388712          -1.514943  \n",
       "2              1.946290       -0.131789          1.198529          -0.293380  \n",
       "3              1.918639       -1.449682         -1.230921          -0.347975  \n",
       "4              1.697439       -0.131789          1.198529          -1.139602  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfZ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = dfZ.drop('HomePriceK_zscore',axis=1)\n",
    "y3 = dfZ['HomePriceK_zscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X3_train shape:  (75, 7)\n",
      "y3_train shape:  (75,)\n",
      "X3_test shape:  (25, 7)\n",
      "y3_test shape:  (25,)\n"
     ]
    }
   ],
   "source": [
    "# Split X and y into X_\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.25, random_state=1)\n",
    "print(\"X3_train shape: \",X3_train.shape) # 75 rows, 7 columns\n",
    "print(\"y3_train shape: \",y3_train.shape) # 75 rows, 1 column\n",
    "print(\"X3_test shape: \",X3_test.shape) # 25 rows, 7 columns\n",
    "print(\"y3_test shape: \",y3_test.shape) # 25 rows, 1 column\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Linear Regression RMSE:  0.26987985082904886\n"
     ]
    }
   ],
   "source": [
    "# fit normalized training data, predict a response and calculate the RMSE\n",
    "lm3 = Ridge()\n",
    "lm3.fit(X3_train,y3_train)\n",
    "y3_predict = lm3.predict(X3_test)\n",
    "regression_model_mse = mean_squared_error(y3_predict, y3_test)\n",
    "print(\"Standardized Linear Regression RMSE: \",math.sqrt(regression_model_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zscore values: [[-0.24361966508402713, 0.9049027201863638, -0.8464714807088045, 0.4056796804902612, -1.5099711746623647, 1.186103749788844, 1.1985285095629954, 606.8165977164775]]\n",
      "\n",
      "\n",
      "[[-0.24361966508402713, 0.9049027201863638, -0.8464714807088045, 0.4056796804902612, -1.5099711746623647, 1.186103749788844, 1.1985285095629954]]\n"
     ]
    }
   ],
   "source": [
    "# give trial data and see how it works\n",
    "\n",
    "Test_data = np.array([[16,1825,6955,3,850,4,3,90000]])\n",
    "Test_data_Z =[]\n",
    "for col in range(8):\n",
    "    Test_data_Z.append((Test_data[0][col]-Mean_z[col])/Std_z[col])\n",
    "Test_data_ZS = [Test_data_Z]\n",
    "print(\"zscore values:\",Test_data_ZS)\n",
    "Test3 = [list(Test_data_ZS[0][0:7])]\n",
    "print (\"\\n\")\n",
    "print (Test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test result predicted (Z-scored) is:  [-0.84955058]\n"
     ]
    }
   ],
   "source": [
    "test_result = lm3.predict(Test3)\n",
    "print (\"Test result predicted (Z-scored) is: \", test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test row with predicted value is: [-0.24361966508402713, 0.9049027201863638, -0.8464714807088045, 0.4056796804902612, -1.5099711746623647, 1.186103749788844, 1.1985285095629954, -0.8495505836775986]\n"
     ]
    }
   ],
   "source": [
    "Test_data_ZS[0][7] = test_result[0]   \n",
    "print (\"test row with predicted value is:\", Test_data_ZS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test result:  [16.0, 1825.0, 6955.0, 3.0, 850.0, 4.0, 3.0, 956.5023094361547]\n",
      "Predicted HomePriceK using Z-Scores:  956.5023094361547\n"
     ]
    }
   ],
   "source": [
    "Predicted_final = []\n",
    "for val in range(8):\n",
    "    Predicted_final.append(Test_data_ZS[0][val]*Std_z[val]+Mean_z[val])\n",
    "print(\"Final test result: \",Predicted_final)\n",
    "print(\"Predicted HomePriceK using Z-Scores: \",Predicted_final[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear_Regression  Standardized RMSE :  0.27608477600543807\n",
      "Predicted HomePriceK:  953.5306412892061\n",
      "\n",
      "\n",
      "Ridge  Standardized RMSE :  0.2728591901776528\n",
      "Predicted HomePriceK:  955.0412487375594\n",
      "\n",
      "\n",
      "Lasso  Standardized RMSE :  0.2601619399492912\n",
      "Predicted HomePriceK:  970.1930582523522\n",
      "\n",
      "\n",
      "LassoLars  Standardized RMSE :  0.9013971282498363\n",
      "Predicted HomePriceK:  1057.4923096316268\n",
      "\n",
      "\n",
      "BayesianRidge  Standardized RMSE :  0.2724671549965388\n",
      "Predicted HomePriceK:  955.2296077804482\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for regression_model in models_list:\n",
    "    regressor = d_models[regression_model]\n",
    "    regressor.fit(X3_train,y3_train)\n",
    "    y3_predict = regressor.predict(X3_test)\n",
    "    regression_model_mse = mean_squared_error(y3_predict, y3_test)\n",
    "    print(regression_model,\" Standardized RMSE : \",math.sqrt(regression_model_mse))\n",
    "    test_result = regressor.predict(Test3)\n",
    "    Test_data_ZS[0][7] = test_result[0]  \n",
    "    Predicted_final2 = []\n",
    "    for val in range(8):\n",
    "        Predicted_final2.append(Test_data_ZS[0][val]*Std_z[val]+Mean_z[val])\n",
    "    print(\"Predicted HomePriceK: \",Predicted_final2[7])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: No outright proof that Standardization is much better than Normalization in terms of predictability.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
